"""Functions to selectively pick up
data from CSVs generated by crawl.py"""

from collections import defaultdict


class UserPageMonthLine:
    """Holds data from a single user-page-month CSV line.
    All attribute values are strings."""

    def __init__(self):
        self.attrs = ["user_id", "is_bot", "page_id",
                      "namespace", "page_is_redirect",
                      "month", "page_month_edits"]
        for attrname in self.attrs:
            setattr(self, attrname, None)

    def from_csv(self, csv_line):
        """Fill in values from provided CSV line"""
        csv = csv_line.strip()
        if not csv[0].isnumeric():
            if not csv.startswith("IP:"):
                return
        pieces = csv.split(",")
        paired = zip(self.attrs, pieces)
        for attrname, val in paired:
            setattr(self, attrname, val)


class BasicStats:
    """Holder for basic stats from
    digesting user-page-months CSV"""

    def __init__(self):
        self.peak_user_page_months = {}
        self.current_peaks = defaultdict(int)
        self.total_revisions = 0
        self.page_ids = set()
        self.user_ids = set()
        self.collect_pages = False
        self.mainspace_only = False
        self.mainspace_user_months = set()
        self.mainspace_page_months = set()
        self.months_by_namespace = defaultdict(int)
        self.edits_by_namespace = defaultdict(int)

    def process_line(self, lineobj):
        """Given a UserPageMonthLine object,
        process it for global stats."""
        if lineobj.user_id is None:
            print("Skipping line object with no user ID")
            return
        self.months_by_namespace[lineobj.namespace] += 1
        count = int(lineobj.page_month_edits)
        self.total_revisions += count
        if self.collect_pages is True:
            if lineobj.namespace == "0" or \
               self.mainspace_only is False:
                self.page_ids.add(lineobj.page_id)
                self.user_ids.add(lineobj.user_id)
        user_month = (lineobj.user_id, lineobj.month)
        page_month = (lineobj.page_id, lineobj.month)
        self.edits_by_namespace[lineobj.namespace] += count
        if count > self.current_peaks[lineobj.namespace]:
            self.peak_user_page_months[lineobj.namespace] = \
                (lineobj.user_id, lineobj.page_id, count)
            self.current_peaks[lineobj.namespace] = count
        if lineobj.namespace == "0":
            if self.collect_pages:
                self.mainspace_user_months.add(user_month)
                self.mainspace_page_months.add(page_month)

    def load_stats(self,
                   months_filepath="user_page_months_output.csv",
                   limit=None):
        """Load dict of users from CSV files in format:
        {(user_id, User)}."""
        with open(months_filepath, encoding="utf-8") as upm_file:
            linecount = 0
            for line in upm_file:
                linecount += 1
                if limit is not None:
                    if linecount > limit:
                        print("Ending at line {}".format(linecount))
                        break
                lineobj = UserPageMonthLine()
                lineobj.from_csv(line)
                if linecount == 1 and lineobj.user_id is None:
                    # skip header
                    continue
                self.process_line(lineobj)


def load_all_upms(filepath):
    """Given a filepath to a user-page-month CSV,
    collect all user-page-months and check for dups."""
    all_upms = set()
    with open(filepath) as lines:
        for line in lines:
            lineobj = UserPageMonthLine()
            lineobj.from_csv(line)
            if lineobj.user_id is None:
                continue
            upm = (lineobj.user_id, lineobj.page_id, lineobj.month)
            if upm in all_upms:
                print("Found duplicate:", str(upm))
            all_upms.add(upm)
    return all_upms
  
